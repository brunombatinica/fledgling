{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cudnn.deterministic = True #???\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classifier\n",
    "\n",
    "Code based on https://github.com/andrei-radulescu-banu/stat453-deep-learning-ss21/blob/main/L15/packed_lstm.ipynb rewrite of raschkas lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "VOCABULARY_SIZE = 20000 #to prevent overfitting\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device(\"cpu\") #\"cuda:1\" if avaialble \n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# url = \"https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\"\n",
    "# filename = \"movie_data.csv.gz\"\n",
    "# urllib.request.urlretrieve(url,filename)\n",
    "\n",
    "# #!python -m wget https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz wget doesnt work (natively works on mac) need to instal module which conda doesnt do right now\n",
    "\n",
    "# #https://ai.standord.edu/~amaas/data/sentiment/ another source of hte dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import shutil\n",
    "\n",
    "# with gzip.open(\"movie_data.csv.gz\",\"rb\") as f_in: #\"rb\" = read bianry mode\n",
    "#         with open(\"movie_data.csv\", \"wb\") as f_out: #write binary\n",
    "#                 shutil.copyfileobj(f_in,f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"movie_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = [\"TEXT_COLUMN_NAME\",\"LABEL_COLUMN_NAME\"]\n",
    "# df.to_csv(\"movie_data.csv\", index = None)\n",
    "\n",
    "# df = pd.read_csv(\"movie_data.csv\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset with Torchdata and new DataPipes API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.datapipes.iter import IterableWrapper, FileOpener\n",
    "\n",
    "datapipe = IterableWrapper([\"movie_data.csv\"])\n",
    "datapipe = FileOpener(datapipe, mode = \"b\")\n",
    "datapipe = datapipe.parse_csv(skip_lines = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 40000\n",
      "Num Validate: 5000\n",
      "Num Test: 5000\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows in dataset\n",
    "N_ROWS = len(list(datapipe))\n",
    "\n",
    "train_dp, valid_dp, test_dp = datapipe.random_split(total_length = N_ROWS, weights = {\"train\": 0.8, \"valid\":0.1, \"test\":0.1}, seed = 0)\n",
    "\n",
    "print(f'Num Train: {len(train_dp)}')\n",
    "print(f'Num Validate: {len(valid_dp)}')\n",
    "print(f'Num Test: {len(test_dp)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the vocabulary class\n",
    "\n",
    "build hte vocabulary based on the top VOCAB_SIZE words. Build_vocab_from_iterator collects the most Hz tokens from the iterator yield_tokens(train_dp and adds special toeksn at the begginign w/o chainign the order of hte supplied tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "#chops up a data iterator into its tokens\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "def get_vocab(train_datapipe):\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(train_datapipe),\n",
    "        specials = [\"<UNK>\",\"<PAD>\"], #?unknown and pad\n",
    "        max_tokens = VOCABULARY_SIZE) #set max vocab to prevent overfitting\n",
    "    vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "    return vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "['<UNK>', '<PAD>', 'the', '.', ',', 'and', 'a', 'of', 'to', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "vocab = get_vocab(train_dp)\n",
    "print(len(vocab))\n",
    "print(vocab.get_itos()[:10]) #integet to sting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default index: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#handling unkown tokens\n",
    "print(f\"Default index: {vocab.get_default_index()}\")\n",
    "vocab[\"124202\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tet_transform and label_transform are callable ojects such as a lambda function here to process the raw test adn label data from the datset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4968, 64, 401, 10, 3847, 0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_transform = lambda x: 1 if x == \"1\" else 0 if x == \"0\" else 1/0 #better to make it throw errors\n",
    "\n",
    "#crazy solution that doesnt actually work\n",
    "# type(lambda: 0)(type((lambda: 0).__code__)(\n",
    "#     1,0,1,1,67,b'|\\0\\202\\1\\0',(),(),('x',),'','',1,b''),{}\n",
    "# )(Exception()) https://stackoverflow.com/questions/8294618/define-a-lambda-expression-that-raises-an-exception\n",
    "\n",
    "print(text_transform(\"Hello my name is Bruno Batinica\"))\n",
    "print(label_transform(\"0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 2\n",
      "the: 2\n",
      "<PAD>: 1\n"
     ]
    }
   ],
   "source": [
    "#converting a string to an integer\n",
    "# A direct way\n",
    "print(f\"the: {vocab['the']}\")\n",
    "\n",
    "# And an indirect way, using get_stoi() to get a dictionary of tokens and values\n",
    "print(f\"the: {vocab.get_stoi()['the']}\") # stoi = string-to-integer\n",
    "\n",
    "# What is the padding value?\n",
    "print(f\"<PAD>: {vocab['<PAD>']}\")\n",
    "PADDING_VALUE=vocab['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<PAD>', 'the', '.', ',', 'and'], dtype='<U5')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_itos = vocab.get_itos()\n",
    "vec_vocab_itos = np.vectorize(lambda x: vocab_itos[x])\n",
    "vec_vocab_itos([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data laoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.utils.data.DataLoader is used to getnerate data batches. Users should customize the databatch by defining a function with teh collate_fn argument in theDataLoader\n",
    "\n",
    "Collate_batch func we process the raw text data adna dd pagging to dynamically match the longest setnece in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list, label_list = [] , []\n",
    "    for (_text,_label) in batch:\n",
    "        processed_text = torch.tensor(text_transform(_text)) #cuts into tokens and converts into a list of integers - see above function\n",
    "        text_list.append(processed_text) #?appends in 1st dimension\n",
    "        label_list.append(label_transform(_label))\n",
    "    return pad_sequence(text_list, padding_value = PADDING_VALUE, batch_first = False).to(DEVICE), torch.tensor(label_list).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to group the texts with simliar length together like the legacy BucketIterator class, first of all, we randomly create multiple POOLS each with size batch_size * 100. Then we sort the samples within the individual pools by length. \n",
    "\n",
    "This idea can be implemented succintly through batch_sampler argument of PyTorch DataLoader\n",
    "\n",
    "batch_sampler accepts \"sampler\" or iterable object that yields indices of the next batch\n",
    "\n",
    "In the code below we implement a generator that yields batch of indexes for which the coresponding batch of data is of similiar length\n",
    "\n",
    "Reduces amount of padding required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler, Dataset\n",
    "\n",
    "#create out own sampler to ensure we function with multiple worker threads\n",
    "#see https://discuss.pytorch.org/t/using-distributedsampler-in-combination-with-batch-sampler-to-make-sure-batches-have-sentences-of-similar-length/119824/3\n",
    "\n",
    "class BatchSamplerSimilarLength(Sampler):\n",
    "    def __init__(self, dataset, batch_size, indices = None, shuffle = True):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # get indices and length\n",
    "        self.indices = [(i, len(tokenizer(s[0]))) for i, s in enumerate(dataset)] #extracts index and length of token\n",
    "        # if indices are passed, then use only the one passed (for ddp)\n",
    "        if indices is not None:\n",
    "            self.indices = torch.tensor(self.indices)[indices].tolist()\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.indices)\n",
    "\n",
    "        pooled_indices = []\n",
    "        #create pool of indices with similiar lengths\n",
    "        for i in range(0, len(self.indices), self.batch_size * 100): #take steps of batch_size * 100\n",
    "            pooled_indices.extend(sorted(self.indices[i:i+self.batch_size * 100], key = lambda x: x[1])) #sorts them by length of the \"sentence\" (x[1]) Only sorted within the pool - but pool is exactly 100 tiems larger than \n",
    "        self.pooled_indices = [x[0] for x in pooled_indices] # returns the indices in order\n",
    "\n",
    "        batches = [self.pooled_indices[i:i+self.batch_size] for i in range(0, len(self.pooled_indices),self.batch_size)] #creates batches of data which have similiar length each batch is size batchsiz\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(batches)\n",
    "\n",
    "        # thisis a generator so make it yield the batch\n",
    "        for batch in batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pooled_indices) // self.batch_size #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1015, 128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dp_list = list(train_dp)\n",
    "valid_dp_list = list(valid_dp)\n",
    "test_dp_list = list(test_dp)\n",
    "\n",
    "train_loader = DataLoader(train_dp_list, \n",
    "                          batch_sampler=BatchSamplerSimilarLength(dataset = train_dp_list, \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                          collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(train_dp_list, \n",
    "                          batch_sampler=BatchSamplerSimilarLength(dataset = valid_dp_list, \n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  shuffle=False),\n",
    "                          collate_fn=collate_batch)\n",
    "test_loader = DataLoader(train_dp_list, \n",
    "                          batch_sampler=BatchSamplerSimilarLength(dataset = test_dp_list, \n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  shuffle=False),\n",
    "                          collate_fn=collate_batch)\n",
    "\n",
    "text_batch, label_batch = next(iter(train_loader))\n",
    "print(text_batch.size())\n",
    "print(label_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T Text matrix size: torch.Size([141, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "T Text matrix size: torch.Size([2623, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "T Text matrix size: torch.Size([214, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "T Text matrix size: torch.Size([140, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "V Text matrix size: torch.Size([763, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "V Text matrix size: torch.Size([1151, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "V Text matrix size: torch.Size([1049, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "V Text matrix size: torch.Size([2623, 128])\n",
      "Target vector size: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# testing the iterators\n",
    "\n",
    "#shuffle so not in order\n",
    "i = 0\n",
    "for text_batch, label_batch in train_loader:\n",
    "    print(f'T Text matrix size: {text_batch.size()}')\n",
    "    print(f'Target vector size: {label_batch.size()}')\n",
    "    i += 1\n",
    "    if i == 4:\n",
    "        break\n",
    "\n",
    "\n",
    "#not shuffled so in order\n",
    "i = 0\n",
    "for text_batch, label_batch in valid_loader:\n",
    "    print(f'V Text matrix size: {text_batch.size()}')\n",
    "    print(f'Target vector size: {label_batch.size()}')\n",
    "    i += 1\n",
    "    if i == 4:\n",
    "        break\n",
    "\n",
    "#number of rows depends on longest document in respective batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERESTING THAT ORDER IS DIFFERNT - BATCH SIZE = NUMBER OF COLUMNS, SENTENCE LENGTH = NUMBER OF ROWS - HMMMMM\n",
    "\n",
    "# MAYBE THIS MAKES SENSE - WHERE EACH WORD IS FED INTO A DIFFERENT NEURON SO EACH INPUT IS ACTUALLY THE EMBEDDING * BATCH SIZE AND THE WORD (SENTENCE LENGTH) IS THE 0th dimensions seperating hte different 2D matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2623, 128])\n",
      "* terrible * * below par * * * not bad * * * * good * * * * * brilliant warning <UNK> spoilers* homosexuality these day ' s is hardly the taboo subject it was over forty years ago . however it must be said that perhaps more so in america than say , over here in the u . k . it can still be a touchy subject . just look at the whole debacle of gay ' s in the <UNK> some years ago in the us . it ' s with ' in and out ' that writer paul <UNK> taps in to the small town mentality of middle america and the way the press in the us ( as well as in the uk ) make such a big deal in outing a celebrity . you need only look at when will young and stephen <UNK> of <UNK> came out of the closet . the movie centres on howard brackett ( kevin kline ) , a high school english teacher in his home town . the local people are preparing themselves for oscar night as one of the nominees cameron drake ( matt dillon ) came from their town and was a former pupil of <UNK> . cameron , who plays a gay soldier in a vietnam epic wins the award only to out howard as being gay during his acceptance speech . this could not come at a worse time for howard who is just day ' s away from marrying his fiance and fellow school teacher emily ( joan cusack ) . as you would expect the media reaction is <UNK> and turn ' s <UNK> life upside down . not only does he try to convince his family and friends that he is not gay but evade sleazy news reporter , peter <UNK> ( tom selleck ) . although this was billed as a screwball comedy it ' s clear that <UNK> and director frank oz are also attempting to be satirical . you only have to look at the early scenes at the oscars <UNK> and the way the people of <UNK> home town as well as the teaching board of the school react to his outing . sadly the film doesn ' t live up to the promise we see early on in the movie . this is a pretty flat attempt to make social commentary out of a wacky comedy . a good cast is sadly wasted on a script that never really delivers the <UNK> amount of laughs and is no where near as insightful as it thinks it . kline gives us the same kind of endearing performance that he gave us in his earlier comedy ' dave ' , making howard an instantly likeable character . cusack too is good value as howard ' s weight obsessed fiance while tom selleck play ' s very well against type as a gay news reporter . bob newhart is a joy also , as the principal of the high school where howard works . it ' s great to see him on the big screen for a change . it ' s a shame that it had to be this . the performances as good as they are can do little to rescue the movie from being a rather dull affair . while a couple of scenes do offer some amusement . namely the inspired scene where howard attempts to make himself seem more manly by listening to a self help tape . there is little to enjoy , and when things can ' t seem to get any worse <UNK> resorts to a sickening finale that <UNK> in to over the top sentiment . i also couldn ' t help but feel that my intelligence was being insulted . <UNK> appears to be too sleazy a character to become the man who put ' s his ethics before getting a good story while <UNK> finally come to the rescue in the film ' s climax seems at first to be too self involved a character to care a <UNK> about what happens to his former teacher . after all it ' s he who caused all the trouble in the first place . ' in and out ' isn ' t exactly dire . but when you consider the likes of <UNK> better work like ' a fish called wanda ' you can ' t help but feel that here is a great talent being sadly wasted . robs rating * * <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(text_batch.shape)\n",
    "\n",
    "print(*vec_vocab_itos(text_batch.to(\"cpu\"))[:,99]) #need to actually look down the rows!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mode - datalaoder and model independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_model(model, num_epochs, train_loader, valid_loader, test_loader, optimizer, device, logging_interval = 50, schedule = None, scheduler_on = \"valid_acc\"):\n",
    "\n",
    "    start_time = time.time()\n",
    "    minibatch_loss_list, train_acc_list, valid_acc_list = [], [] ,[]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train() #set model in training mode\n",
    "\n",
    "        for batch_idx, (features,targets) in tqdm(enumerate(train_loader)):\n",
    "\n",
    "            #print(features)\n",
    "            \n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            #forward and backprop\n",
    "            logits = model(features)\n",
    "\n",
    "            #print(logits)\n",
    "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            #update paraemeters\n",
    "            optimizer.zero_grad()\n",
    "            optimizer.step()\n",
    "\n",
    "            #logging\n",
    "            minibatch_loss_list.append(loss.item())\n",
    "            if not batch_idx % logging_interval:\n",
    "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
    "                      f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
    "                      f'| Loss: {loss:.4f}')\n",
    "\n",
    "        #at the end of each epoch\n",
    "\n",
    "        model.eval() #set to evaluation mode\n",
    "        with torch.no_grad():  # save memory during inference\n",
    "                train_acc = compute_accuracy(model, train_loader, device=device)\n",
    "                valid_acc = compute_accuracy(model, valid_loader, device=device)\n",
    "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
    "                    f'| Train: {train_acc :.2f}% '\n",
    "                    f'| Validation: {valid_acc :.2f}%')\n",
    "                train_acc_list.append(train_acc)\n",
    "                valid_acc_list.append(valid_acc)\n",
    "\n",
    "\n",
    "        elapsed = (time.time() - start_time)/60\n",
    "        print(f'Time elapsed: {elapsed:.2f} min')\n",
    "\n",
    "        if scheduler is not None:\n",
    "\n",
    "            if scheduler_on == 'valid_acc':\n",
    "                scheduler.step(valid_acc_list[-1])\n",
    "            elif scheduler_on == 'minibatch_loss':\n",
    "                scheduler.step(minibatch_loss_list[-1])\n",
    "            else:\n",
    "                raise ValueError(f'Invalid `scheduler_on` choice.')\n",
    "\n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Total Training Time: {elapsed:.2f} min')\n",
    "\n",
    "    test_acc = compute_accuracy(model, test_loader, device=device)\n",
    "    print(f'Test accuracy {test_acc :.2f}%')\n",
    "\n",
    "    return minibatch_loss_list, train_acc_list, valid_acc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Actually writing the RNN model**\n",
    "\n",
    "actually an lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        # #poor performance when just using RNN\n",
    "        # self.rnn = torch.nn.RNN(embedding_dim,  \n",
    "        #                         hidden_dim,\n",
    "        #                         nonlinearity = \"relu\")\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                hidden_dim) \n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim) #fully connected - hidden dim to class labels\n",
    "\n",
    "    def forward(self, text):\n",
    "        #text dim; [sentence lentgh, batch size]\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded dim: [sentence length, batchsize, embedding dim]\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        #output dim: [sentence length, batch size, hidden dim]\n",
    "        # this is the y matrix - one for each word\n",
    "\n",
    "        # hidden dim: [1, batchsize, hidden dim] #one for the network\n",
    "\n",
    "        #hidden = the hidden state of the RNN - this would usually be fed into the next neuron\n",
    "\n",
    "        hidden.squeeze_(0) #squeezes out the 0th dimension\n",
    "        #hidden dim: [batchsize, hidden dim]\n",
    "\n",
    "        output = self.fc(hidden)\n",
    "\n",
    "\n",
    "        #Many to one network so we ignore most of hte outputs\n",
    "        #in this one we actually ignore all the outputs and just use the hidden state\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 0000/0312 | Loss: 0.6985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [01:01,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 0100/0312 | Loss: 0.6922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [02:06,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 0200/0312 | Loss: 0.6930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [03:01,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 0300/0312 | Loss: 0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [03:07,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Train: 50.05% | Validation: 50.86%\n",
      "Time elapsed: 4.89 min\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[207], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m LEARNING_RATE)\n\u001b[0;32m     10\u001b[0m schedule \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optimizer,\n\u001b[0;32m     11\u001b[0m                                                       factor \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                                       mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m                                                       verbose \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 15\u001b[0m minibatch_loss_list, train_acc_list, valid_acc_list \u001b[39m=\u001b[39m train_model(\n\u001b[0;32m     16\u001b[0m     model \u001b[39m=\u001b[39;49m model,\n\u001b[0;32m     17\u001b[0m     num_epochs \u001b[39m=\u001b[39;49m NUM_EPOCHS,\n\u001b[0;32m     18\u001b[0m     train_loader \u001b[39m=\u001b[39;49m train_loader,\n\u001b[0;32m     19\u001b[0m     valid_loader \u001b[39m=\u001b[39;49m valid_loader,\n\u001b[0;32m     20\u001b[0m     test_loader \u001b[39m=\u001b[39;49m test_loader,\n\u001b[0;32m     21\u001b[0m     optimizer \u001b[39m=\u001b[39;49m optimizer,\n\u001b[0;32m     22\u001b[0m     device \u001b[39m=\u001b[39;49m DEVICE,\n\u001b[0;32m     23\u001b[0m     logging_interval \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m\n\u001b[0;32m     24\u001b[0m )\n",
      "Cell \u001b[1;32mIn[205], line 54\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, num_epochs, train_loader, valid_loader, test_loader, optimizer, device, logging_interval, schedule, scheduler_on)\u001b[0m\n\u001b[0;32m     51\u001b[0m elapsed \u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\u001b[39m/\u001b[39m\u001b[39m60\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTime elapsed: \u001b[39m\u001b[39m{\u001b[39;00melapsed\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m \u001b[39mif\u001b[39;00m scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[39mif\u001b[39;00m scheduler_on \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvalid_acc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     57\u001b[0m         scheduler\u001b[39m.\u001b[39mstep(valid_acc_list[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scheduler' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(input_dim = len(vocab),\n",
    "            embedding_dim = EMBEDDING_DIM,\n",
    "            hidden_dim = HIDDEN_DIM,\n",
    "            output_dim = NUM_CLASSES) #could use 1 for bianry classification)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                      factor = 0.1,\n",
    "                                                      mode = \"max\",\n",
    "                                                      verbose = True)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model = model,\n",
    "    num_epochs = NUM_EPOCHS,\n",
    "    train_loader = train_loader,\n",
    "    valid_loader = valid_loader,\n",
    "    test_loader = test_loader,\n",
    "    optimizer = optimizer,\n",
    "    device = DEVICE,\n",
    "    logging_interval = 100\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
