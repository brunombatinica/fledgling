{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Deep Learning (Spring 2021)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom DataLoader Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration of how we can efficiently iterate through custom (image) datasets. For this, suppose \n",
    "- mnist_train, mnist_valid, and mnist_test are image folders you created with your own custom images\n",
    "- mnist_train.csv, mnist_valid.csv, and mnist_test.csv are tables that store the image names with their associated class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.2\n",
      "IPython version      : 7.20.0\n",
      "\n",
      "torch     : 1.9.0a0+d819a21\n",
      "pandas    : 1.2.2\n",
      "numpy     : 1.20.1\n",
      "matplotlib: 3.3.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch,pandas,numpy,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Inspecting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x143fc38e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open('mnist_train/1.png')\n",
    "plt.imshow(im, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Dimensions (28, 28)\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1  18  38 136 227 255\n",
      "  254 132   0  90 136  98   3   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  82 156 253 253 253 253 253\n",
      "  253 249 154 219 253 253  35   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  40 150 244 253 253 253 253 253 253\n",
      "  253 253 253 253 253 253  35   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  74 237 253 253 253 253 253 203 182 242\n",
      "  253 253 253 253 253 230  25   0   0   0]\n",
      " [  0   0   0   0   0   0   0  13 200 253 253 253 168 164  91  14  64 246\n",
      "  253 253 253 195  79  32   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  21 219 253 253 159   2   0   0 103 233 253\n",
      "  253 253 177  10   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 171 253 253 147   0   1 155 250 253 253\n",
      "  251 126   5   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 101 236 253 206  32 152 253 253 253 253\n",
      "  130   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  91 253 253 253 253 253 253 241 113\n",
      "    9   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  91 243 253 253 253 253 239  81   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 207 253 253 253 253 158   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 207 253 253 253 253 121   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  24 145 249 253 253 253 253 194   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  59 253 253 253 253 253 253 224  30   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5 181 253 253 241 114 240 253 253 136   5\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  36 253 253 253 125   0  65 253 253 253  41\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  67 253 253 253  29   2 138 253 253 253  41\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  60 253 253 253 207 202 253 253 253 192   9\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5 183 253 253 253 253 253 253 230  52   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  62 253 253 253 253 242 116  13   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "im_array = np.array(im)\n",
    "print('Array Dimensions', im_array.shape)\n",
    "print()\n",
    "print(im_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label File Name\n",
       "0            5     0.png\n",
       "1            8     1.png\n",
       "2            8     2.png\n",
       "3            0     3.png\n",
       "4            9     4.png"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('mnist_train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>256.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>257.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>258.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>259.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>260.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label File Name\n",
       "0            0   256.png\n",
       "1            8   257.png\n",
       "2            7   258.png\n",
       "3            4   259.png\n",
       "4            7   260.png"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv('mnist_valid.csv')\n",
    "print(df_valid.shape)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>512.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>513.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>514.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>515.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>516.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label File Name\n",
       "0            4   512.png\n",
       "1            0   513.png\n",
       "2            6   514.png\n",
       "3            8   515.png\n",
       "4            4   516.png"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('mnist_test.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = df['File Name']\n",
    "        self.y = df['Class Label']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Custom Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Note that transforms.ToTensor()\n",
    "# already divides pixels by 255. internally\n",
    "\n",
    "custom_transform = transforms.Compose([#transforms.Lambda(lambda x: x/255.), # not necessary\n",
    "                                       transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "train_dataset = MyDataset(csv_path='mnist_train.csv',\n",
    "                          img_dir='mnist_train',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=32,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True, # want to shuffle the dataset\n",
    "                          num_workers=0) # number processes/CPUs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = MyDataset(csv_path='mnist_valid.csv',\n",
    "                          img_dir='mnist_valid',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=100,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = MyDataset(csv_path='mnist_test.csv',\n",
    "                         img_dir='mnist_test',\n",
    "                         transform=custom_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=100,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Iterating Through the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 1 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 2 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 3 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 4 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 5 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 6 | Batch size: 32\n",
      "Epoch: 1 | Batch index: 7 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 1 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 2 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 3 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 4 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 5 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 6 | Batch size: 32\n",
      "Epoch: 2 | Batch index: 7 | Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n"
     ]
    }
   ],
   "source": [
    "x_image_as_vector = x.view(-1, 28*28)\n",
    "print(x_image_as_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
